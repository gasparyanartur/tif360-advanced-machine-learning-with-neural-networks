{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "board\n",
      "[[-1 -1 -1]\n",
      " [-1  1 -1]\n",
      " [-1  1  1]]\n",
      "type\n",
      "1\n",
      "enc_board\n",
      "[False False False False  True False False  True  True]\n",
      "enc_types\n",
      "[False  True False False False]\n",
      "occ\n",
      "[False False False False  True False False  True  True False  True False\n",
      " False False]\n",
      "pow\n",
      "[   1    2    4    8   16   32   64  128  256  512 1024 2048 4096 8192]\n",
      "code\n",
      "1424\n",
      "func output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1424"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode type\n",
    "\n",
    "n_types = 5\n",
    "t = 1\n",
    "board = np.array([[-1, -1, -1], [-1, 1, -1], [-1, 1, 1]])\n",
    "\n",
    "print(\"board\")\n",
    "print(board)\n",
    "print(\"type\")\n",
    "print(t)\n",
    "\n",
    "enc_types = np.zeros(n_types, dtype=bool)\n",
    "enc_types[t] = 1\n",
    "\n",
    "enc_board = (board==1).flatten()\n",
    "print(\"enc_board\")\n",
    "print(enc_board)\n",
    "\n",
    "print(\"enc_types\")\n",
    "print(enc_types)\n",
    "\n",
    "occ = np.hstack((enc_board, enc_types))\n",
    "print(\"occ\")\n",
    "print(occ)\n",
    "\n",
    "pow = 1<<np.arange(occ.size)\n",
    "print(\"pow\")\n",
    "print(pow)\n",
    "\n",
    "code = pow@occ\n",
    "print(\"code\")\n",
    "print(code)\n",
    "\n",
    "\n",
    "def encode_state(n_tiles, board, tile_type):\n",
    "    enc_types = np.zeros(n_tiles, dtype=bool)\n",
    "    enc_types[tile_type] = 1\n",
    "    enc_board = (board==1).flatten()\n",
    "\n",
    "    occ = np.hstack((enc_board, enc_types))\n",
    "    pow = 1 << np.arange(occ.size)\n",
    "    code = pow@occ\n",
    "\n",
    "    return code\n",
    "\n",
    "\n",
    "print(\"func output\")\n",
    "encode_state(n_types, board, t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [0, 2],\n",
       "       [0, 3],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 2],\n",
       "       [1, 3],\n",
       "       [2, 0],\n",
       "       [2, 1],\n",
       "       [2, 2],\n",
       "       [2, 3],\n",
       "       [3, 0],\n",
       "       [3, 1],\n",
       "       [3, 2],\n",
       "       [3, 3],\n",
       "       [4, 0],\n",
       "       [4, 1],\n",
       "       [4, 2],\n",
       "       [4, 3],\n",
       "       [5, 0],\n",
       "       [5, 1],\n",
       "       [5, 2],\n",
       "       [5, 3],\n",
       "       [6, 0],\n",
       "       [6, 1],\n",
       "       [6, 2],\n",
       "       [6, 3],\n",
       "       [7, 0],\n",
       "       [7, 1],\n",
       "       [7, 2],\n",
       "       [7, 3],\n",
       "       [8, 0],\n",
       "       [8, 1],\n",
       "       [8, 2],\n",
       "       [8, 3],\n",
       "       [9, 0],\n",
       "       [9, 1],\n",
       "       [9, 2],\n",
       "       [9, 3]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_pos = 10\n",
    "n_ori = 4\n",
    "\n",
    "tile_positions = np.arange(n_pos)\n",
    "tile_orientations = np.arange(n_ori)\n",
    "\n",
    "tile_positions = np.repeat(np.arange(n_pos, dtype=int), n_ori)\n",
    "tile_orientations = np.tile(np.arange(n_ori, dtype=int), n_pos)\n",
    "actions = np.vstack((tile_positions, tile_orientations)).T\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36893488147419103231"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gmpy2\n",
    "\n",
    "int(gmpy2.pack([1 for _ in range(65)], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class SmallStateAutoEncoder(nn.Module):\n",
    "    def __init__(self, d_L, d_H) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 2, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, padding=1),\n",
    "            nn.Flatten(1),   # dim \n",
    "            nn.Linear(256, d_H),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_H, d_L),\n",
    "            nn.ReLU(),\n",
    "        )        \n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(d_L, d_H),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_H, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (16, 4, 4)),\n",
    "            nn.ConvTranspose2d(16, 1, 1, stride=1, padding=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return torch.tanh(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.choice([-1, 1], size=(128, 128, 1, 4, 4))\n",
    "data = torch.Tensor(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0/100\n",
      "loss: 0.9858828182332218\n",
      "epoch: 1/100\n",
      "loss: 0.8289815257303417\n",
      "epoch: 2/100\n",
      "loss: 0.7625264227390289\n",
      "epoch: 3/100\n",
      "loss: 0.751639848574996\n",
      "epoch: 4/100\n",
      "loss: 0.7457544035278261\n",
      "epoch: 5/100\n",
      "loss: 0.7406589705497026\n",
      "epoch: 6/100\n",
      "loss: 0.7357798488810658\n",
      "epoch: 7/100\n",
      "loss: 0.7305281576700509\n",
      "epoch: 8/100\n",
      "loss: 0.7234605723060668\n",
      "epoch: 9/100\n",
      "loss: 0.7121640909463167\n",
      "epoch: 10/100\n",
      "loss: 0.6876952759921551\n",
      "epoch: 11/100\n",
      "loss: 0.6226979345083237\n",
      "epoch: 12/100\n",
      "loss: 0.5616236794739962\n",
      "epoch: 13/100\n",
      "loss: 0.5447219354100525\n",
      "epoch: 14/100\n",
      "loss: 0.5361014707013965\n",
      "epoch: 15/100\n",
      "loss: 0.5287122414447367\n",
      "epoch: 16/100\n",
      "loss: 0.5221467805095017\n",
      "epoch: 17/100\n",
      "loss: 0.5162966407369822\n",
      "epoch: 18/100\n",
      "loss: 0.5110815574880689\n",
      "epoch: 19/100\n",
      "loss: 0.5063164562452585\n",
      "epoch: 20/100\n",
      "loss: 0.5019847068469971\n",
      "epoch: 21/100\n",
      "loss: 0.49783361214213073\n",
      "epoch: 22/100\n",
      "loss: 0.4937441870570183\n",
      "epoch: 23/100\n",
      "loss: 0.4896081027109176\n",
      "epoch: 24/100\n",
      "loss: 0.48523278813809156\n",
      "epoch: 25/100\n",
      "loss: 0.4805515627376735\n",
      "epoch: 26/100\n",
      "loss: 0.47585118166171014\n",
      "epoch: 27/100\n",
      "loss: 0.4714798303321004\n",
      "epoch: 28/100\n",
      "loss: 0.4673185970168561\n",
      "epoch: 29/100\n",
      "loss: 0.4632946881465614\n",
      "epoch: 30/100\n",
      "loss: 0.4593595906626433\n",
      "epoch: 31/100\n",
      "loss: 0.4554243884049356\n",
      "epoch: 32/100\n",
      "loss: 0.451396060641855\n",
      "epoch: 33/100\n",
      "loss: 0.44763769931159914\n",
      "epoch: 34/100\n",
      "loss: 0.44407637882977724\n",
      "epoch: 35/100\n",
      "loss: 0.44059522240422666\n",
      "epoch: 36/100\n",
      "loss: 0.4371852888725698\n",
      "epoch: 37/100\n",
      "loss: 0.433703999966383\n",
      "epoch: 38/100\n",
      "loss: 0.42999151279218495\n",
      "epoch: 39/100\n",
      "loss: 0.4262532265856862\n",
      "epoch: 40/100\n",
      "loss: 0.4223914700560272\n",
      "epoch: 41/100\n",
      "loss: 0.41839985246770084\n",
      "epoch: 42/100\n",
      "loss: 0.41446853382512927\n",
      "epoch: 43/100\n",
      "loss: 0.41061976621858776\n",
      "epoch: 44/100\n",
      "loss: 0.4068607303779572\n",
      "epoch: 45/100\n",
      "loss: 0.40333496243692935\n",
      "epoch: 46/100\n",
      "loss: 0.3999164227861911\n",
      "epoch: 47/100\n",
      "loss: 0.3964634439907968\n",
      "epoch: 48/100\n",
      "loss: 0.39301059930585325\n",
      "epoch: 49/100\n",
      "loss: 0.38912536669522524\n",
      "epoch: 50/100\n",
      "loss: 0.3848749380558729\n",
      "epoch: 51/100\n",
      "loss: 0.380517530022189\n",
      "epoch: 52/100\n",
      "loss: 0.37611062126234174\n",
      "epoch: 53/100\n",
      "loss: 0.37191356462426484\n",
      "epoch: 54/100\n",
      "loss: 0.3680024752393365\n",
      "epoch: 55/100\n",
      "loss: 0.36421516072005033\n",
      "epoch: 56/100\n",
      "loss: 0.3608072870410979\n",
      "epoch: 57/100\n",
      "loss: 0.35748240374960005\n",
      "epoch: 58/100\n",
      "loss: 0.35436375462450087\n",
      "epoch: 59/100\n",
      "loss: 0.3513139358256012\n",
      "epoch: 60/100\n",
      "loss: 0.3483295254409313\n",
      "epoch: 61/100\n",
      "loss: 0.3454344442579895\n",
      "epoch: 62/100\n",
      "loss: 0.3424956921953708\n",
      "epoch: 63/100\n",
      "loss: 0.33963268622756004\n",
      "epoch: 64/100\n",
      "loss: 0.33680451288819313\n",
      "epoch: 65/100\n",
      "loss: 0.33396418509073555\n",
      "epoch: 66/100\n",
      "loss: 0.331235493067652\n",
      "epoch: 67/100\n",
      "loss: 0.32873359438963234\n",
      "epoch: 68/100\n",
      "loss: 0.32642086572013795\n",
      "epoch: 69/100\n",
      "loss: 0.3241861283313483\n",
      "epoch: 70/100\n",
      "loss: 0.3220516585279256\n",
      "epoch: 71/100\n",
      "loss: 0.32018832908943295\n",
      "epoch: 72/100\n",
      "loss: 0.318322153063491\n",
      "epoch: 73/100\n",
      "loss: 0.3167355360928923\n",
      "epoch: 74/100\n",
      "loss: 0.3150814021937549\n",
      "epoch: 75/100\n",
      "loss: 0.31357743754051626\n",
      "epoch: 76/100\n",
      "loss: 0.3121305333916098\n",
      "epoch: 77/100\n",
      "loss: 0.3107411388773471\n",
      "epoch: 78/100\n",
      "loss: 0.30938729061745107\n",
      "epoch: 79/100\n",
      "loss: 0.30808963323943317\n",
      "epoch: 80/100\n",
      "loss: 0.3068557037040591\n",
      "epoch: 81/100\n",
      "loss: 0.30561723187565804\n",
      "epoch: 82/100\n",
      "loss: 0.3044175012037158\n",
      "epoch: 83/100\n",
      "loss: 0.3032192811369896\n",
      "epoch: 84/100\n",
      "loss: 0.3021035494748503\n",
      "epoch: 85/100\n",
      "loss: 0.30102222319692373\n",
      "epoch: 86/100\n",
      "loss: 0.2999503668397665\n",
      "epoch: 87/100\n",
      "loss: 0.2989326403476298\n",
      "epoch: 88/100\n",
      "loss: 0.2979109506122768\n",
      "epoch: 89/100\n",
      "loss: 0.2969279794488102\n",
      "epoch: 90/100\n",
      "loss: 0.29598420951515436\n",
      "epoch: 91/100\n",
      "loss: 0.2950223565567285\n",
      "epoch: 92/100\n",
      "loss: 0.2940429726149887\n",
      "epoch: 93/100\n",
      "loss: 0.29311324562877417\n",
      "epoch: 94/100\n",
      "loss: 0.29221998807042837\n",
      "epoch: 95/100\n",
      "loss: 0.2912862724624574\n",
      "epoch: 96/100\n",
      "loss: 0.29040703317150474\n",
      "epoch: 97/100\n",
      "loss: 0.2895200264174491\n",
      "epoch: 98/100\n",
      "loss: 0.2886578682810068\n",
      "epoch: 99/100\n",
      "loss: 0.28781576245091856\n"
     ]
    }
   ],
   "source": [
    "ae = SmallStateAutoEncoder(8, 64).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optim = torch.optim.Adam(ae.parameters(), lr=2E-4)\n",
    "\n",
    "losses = []\n",
    "run_loss = 0\n",
    "n_epochs = 100\n",
    "\n",
    "ae.train()\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}/{n_epochs}')\n",
    "\n",
    "    run_loss = 0\n",
    "    for x in data:\n",
    "        optim.zero_grad()\n",
    "        x = x.to(device)\n",
    "\n",
    "        y = ae(x)\n",
    "\n",
    "        loss = loss_fn(y, x)\n",
    "        run_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    train_loss = run_loss / len(data)\n",
    "\n",
    "    print(f'loss: {train_loss}')\n",
    "    losses.append(train_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.689078  33.312435   0.         7.3474307  0.        15.756741\n",
      "  16.56565    3.162099 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c045a839a0>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ex_grid = np.array([[-1, 1, 1, -1], [1, -1, 1, 1], [-1, 1, 1, 1], [-1, 1, 1, 1]])\n",
    "ex_grid = ex_grid.reshape(1, 1, 4, 4)\n",
    "ex_grid = torch.Tensor(ex_grid).to(device)\n",
    "\n",
    "ae.eval()\n",
    "ex_y = torch.sgn(ae(ex_grid))\n",
    "print(ae.encoder(ex_grid).detach().cpu().numpy())\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(ex_grid.detach().cpu().numpy().squeeze())\n",
    "ax2.imshow(ex_y.detach().cpu().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class LargeStateAutoEncoder(nn.Module):\n",
    "    def __init__(self, d_L, d_H) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 256, 4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, padding=1),\n",
    "            nn.Flatten(1),   # dim \n",
    "            nn.Linear(4096, d_H),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_H, d_L),\n",
    "            nn.ReLU(),\n",
    "        )        \n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(d_L, d_H),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_H, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (256, 8, 8)),\n",
    "            nn.ConvTranspose2d(256, 1, 1, stride=1, padding=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return torch.tanh(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.choice([-1, 1], size=(128, 128, 1, 8, 8))\n",
    "data = torch.Tensor(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0/100\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x6400 and 4096x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[227], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     16\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 18\u001b[0m y \u001b[39m=\u001b[39m ae(x)\n\u001b[0;32m     20\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y, x)\n\u001b[0;32m     21\u001b[0m run_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\gaspa\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[225], line 32\u001b[0m, in \u001b[0;36mLargeStateAutoEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 32\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[0;32m     33\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(x)\n\u001b[0;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtanh(x)\n",
      "File \u001b[1;32mc:\\Users\\gaspa\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\gaspa\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gaspa\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\gaspa\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x6400 and 4096x64)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ae = LargeStateAutoEncoder(8, 64).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optim = torch.optim.Adam(ae.parameters(), lr=2E-4)\n",
    "\n",
    "losses = []\n",
    "run_loss = 0\n",
    "n_epochs = 100\n",
    "\n",
    "ae.train()\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}/{n_epochs}')\n",
    "\n",
    "    run_loss = 0\n",
    "    for x in data:\n",
    "        optim.zero_grad()\n",
    "        x = x.to(device)\n",
    "\n",
    "        y = ae(x)\n",
    "\n",
    "        loss = loss_fn(y, x)\n",
    "        run_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    train_loss = run_loss / len(data)\n",
    "\n",
    "    print(f'loss: {train_loss}')\n",
    "    losses.append(train_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "<>:7: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "C:\\Users\\gaspa\\AppData\\Local\\Temp\\ipykernel_20664\\2040847715.py:7: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  [-1, -1, -1, -1, -1, 1, 1, 1]\n",
      "C:\\Users\\gaspa\\AppData\\Local\\Temp\\ipykernel_20664\\2040847715.py:7: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  [-1, -1, -1, -1, -1, 1, 1, 1]\n",
      "C:\\Users\\gaspa\\AppData\\Local\\Temp\\ipykernel_20664\\2040847715.py:7: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  [-1, -1, -1, -1, -1, 1, 1, 1]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[215], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m ex_grid \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\n\u001b[0;32m      4\u001b[0m     [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[0;32m      5\u001b[0m     [\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[0;32m      6\u001b[0m     [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m],\n\u001b[1;32m----> 7\u001b[0m     [\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m]\n\u001b[0;32m      8\u001b[0m     [\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m],\n\u001b[0;32m      9\u001b[0m     [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m],\n\u001b[0;32m     10\u001b[0m     [\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[0;32m     11\u001b[0m     [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m]])\n\u001b[0;32m     12\u001b[0m ex_grid \u001b[39m=\u001b[39m ex_grid\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m)\n\u001b[0;32m     13\u001b[0m ex_grid \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor(ex_grid)\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ex_grid = np.array([\n",
    "    [-1, 1, 1, -1, 1, 1, 1, -1],\n",
    "    [1, -1, 1, 1, 1, 1, -1, -1],\n",
    "    [-1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [-1, -1, -1, -1, -1, 1, 1, 1],\n",
    "    [1, 1, 1, -1, 1, -1, -1, 1],\n",
    "    [-1, -1, 1, -1, 1, 1, -1, 1],\n",
    "    [1, -1, -1, 1, 1, 1, 1, -1],\n",
    "    [-1, -1, -1, -1, 1, 1, 1, 1]])\n",
    "ex_grid = ex_grid.reshape(1, 1, 8, 8)\n",
    "ex_grid = torch.Tensor(ex_grid).to(device)\n",
    "\n",
    "ae.eval()\n",
    "ex_y = torch.sgn(ae(ex_grid))\n",
    "print(ae.encoder(ex_grid).detach().cpu().numpy())\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(ex_grid.detach().cpu().numpy().squeeze())\n",
    "ax2.imshow(ex_y.detach().cpu().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
